from pyspark.ml.feature import StringIndexer, VectorAssembler
from pyspark.ml import Pipeline
from pyspark.sql.functions import col
from pyspark.ml.classification import GBTClassifier # No native CatBoost in PySpark

# 1. String Indexing
indexers = [StringIndexer(inputCol=column, outputCol=column+"_index").fit(df) for column in ["A", "B", "C", "Label"]]

# 2. Vector Assembling
feature_columns = ["A_index", "B_index", "C_index"]
assembler = VectorAssembler(inputCols=feature_columns, outputCol="features")

# 3. Pipeline for transformations
pipeline = Pipeline(stages=indexers + [assembler])
df_transformed = pipeline.fit(df).transform(df)

# 4. Splitting Data
(training_data, test_data) = df_transformed.randomSplit([0.8, 0.2])

# 5. Train a Gradient Boosting (or any other classifier, as CatBoost is not natively supported in PySpark)
gbt = GBTClassifier(labelCol="Label_index", featuresCol="features", maxIter=10)
model = gbt.fit(training_data)

# 6. Model Evaluation
predictions = model.transform(test_data)
predictions.select("prediction", "Label_index", "features").show(5)

# You might want to add an evaluation metric here based on your requirements, like accuracy, precision, recall, etc.
